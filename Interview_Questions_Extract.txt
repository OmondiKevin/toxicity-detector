NAME:                                                                                 
Test Instructions: 
Preparation & Modeling: 2–3 hours
Deployment Concept Draft: 1 hour
Presentation: 20 Mins
1. Dataset
Use a merged dataset combining the Hate Speech and Offensive Language Dataset and Toxic Comment Classification dataset provided.
2. Tasks
A. Data Preprocessing
Clean text data (remove URLs, mentions, hashtags, emojis, punctuations).
Apply text normalization (lowercasing, stemming/lemmatization).
Tokenize and vectorize (use TF-IDF or Word Embeddings like Word2Vec or GloVe).
B. Model Building
Build a multi-label text classification model using any deep learning framework (e.g., TensorFlow, PyTorch).
Recommended models: LSTM, GRU, Transformer, or fine-tune a pre-trained model (e.g., BERT).
Output labels: toxic, severe toxic, obscene, threat, insult, identity_hate, non_offensive.
C. Model Evaluation
Use metrics: Precision, Recall, F1 Score, ROC-AUC.
Visualize confusion matrices for each class.
Compare performance across at least two different model architectures (e.g., LSTM vs BERT).
D. Deployment (Concept Only)
Design an API outline for real-time content moderation:
Expected API input (JSON format)
Expected API output (JSON with classification probabilities and suggested action: flag, block, allow)
Deploy the model using Flask, FastAPI, or Streamlit.
3. Deliverables
Python scripts or Jupyter Notebook with clear documentation.
A short report (1–2 pages) covering:
Approach used
Challenges faced
Model performance summary
Improvement suggestions for production-level systems
(Optional Bonus) A small Streamlit or Flask demo.