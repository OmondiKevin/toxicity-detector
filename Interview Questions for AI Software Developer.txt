NAME:

Test Instructions:

Preparation & Modeling: 2-3 hours

Deployment Concept Draft: 1 hour

Presentation: 20 Mins

1. Dataset

Use a merged dataset combining the Hate Speech and Offensive Language Dataset and Toxic Comment Classification dataset provided.

2. Tasks

A. Data Preprocessing

Clean text data (remove URLs, mentions, hashtags, emojis, punctuations).

Apply text normalization (lowercasing, stemming/lemmatization).

Tokenize and vectorize (use TF-IDF or Word Embeddings like Word2Vec or GloVe).

B. Model Building

Build a multi-label text classification model using any deep learning framework (e.g., TensorFlow, PyTorch).

Recommended models: LSTM, GRU, Transformer, or fine-tune a pre-trained model (e.g., BERT).

Output labels: toxic, severe toxic, obscene, threat, insult, identity_hate, non_offensive.

C. Model Evaluation

Use metrics: Precision, Recall, F1 Score, ROC-AUC.

Visualize confusion matrices for each class.

Compare performance across at least two different model architectures (e.g., LSTM vs BERT).

D. Deployment (Concept Only)

Design an API outline for real-time content moderation:

Expected API input (JSON format)

Expected API output (JSON with classification probabilities and suggested action: flag, block, allow)

Deploy the model using Flask, FastAPI, or Streamlit.

3. Deliverables

Python scripts or Jupyter Notebook with clear documentation.

A short report (1-2 pages) covering:

Approach used

Challenges faced

Training on the CPU (Apple Silicon M1 Chip with 8 GB RAM) is not good enough for conclusive results. All these are baseline results and can be improved with time.

Model performance summary

Improvement suggestions for production-level systems

(Optional Bonus) A small Streamlit or Flask demo.

Evaluation Criteria	Weight

Data Preprocessing Techniques	20%

Model Accuracy and Performance	30%

Clarity of Code and Documentation	20%

API/Deployment Design	15%

Innovation and Bonus Features	15%

How to present this in your interview

You can frame it like this:

We built an efficient LSTM baseline (~4.8M parameters) that achieved a validation loss of 0.3622 and a test loss of 0.3624 after 6 epochs with early stopping. The small gap between validation and test performance indicates good generalization. For deployment, this LSTM model is lightweight and practical. However, we would expect a transformer-based fine-tuned model like BERT to outperform it in absolute accuracy.

Our BERT model shows steadily decreasing training loss (0.28 -> 0.14), but validation loss increases (0.37 -> 0.49), triggering early stopping after 3 epochs. This indicates overfitting - the model is memorizing training data rather than generalizing. We can address this with lower learning rates, stronger regularization, longer patience, and evaluating with task-specific metrics like macro F1 instead of loss alone.